{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q keras-tuner"
      ],
      "metadata": {
        "id": "GuoJD6zgAzjc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwL2eR5iApqh",
        "outputId": "51aead40-dd12-48f0-853b-e4cd4a501c45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import keras_tuner as kt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the JSON dataset\n",
        "file_path = '/content/drive/MyDrive/DL/DLWeek5/DeteksiSarkasme.json'\n",
        "data = pd.read_json(file_path, lines=True)"
      ],
      "metadata": {
        "id": "-i0fLcpSBm_K"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop any rows with missing headline or target values\n",
        "data = data.dropna(subset=['headline', 'is_sarcastic'])\n",
        "\n",
        "# Use the 'headline' as the input and 'is_sarcastic' as the target\n",
        "X = data['headline']\n",
        "y = data['is_sarcastic']\n",
        "\n",
        "# Tokenize the text data\n",
        "num_words = 10000  # Limiting the vocabulary to the top 10,000 words\n",
        "maxlen = 500  # Maximum length of the text sequences (padding/truncating to this length)\n",
        "\n",
        "tokenizer = Tokenizer(num_words=num_words)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X_seq = tokenizer.texts_to_sequences(X)\n",
        "X_pad = pad_sequences(X_seq, maxlen=maxlen)\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "d8s07yTRB0Zx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to create the BiRNN model\n",
        "def create_birnn_model(hp):\n",
        "    embedding_dim = hp.Int('embedding_dim', min_value=64, max_value=128, step=64)\n",
        "    rnn_units = hp.Int('rnn_units', min_value=64, max_value=256, step=64)\n",
        "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.3, step=0.1)\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=maxlen),\n",
        "        layers.Bidirectional(layers.LSTM(rnn_units, dropout=dropout_rate)),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Use Hyperband for hyperparameter tuning\n",
        "tuner = kt.Hyperband(\n",
        "    create_birnn_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    hyperband_iterations=2,\n",
        "    directory='my_dir',\n",
        "    project_name='sarcasm_detection_tuning'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IbDOkrgB3Mh",
        "outputId": "01b568d2-798c-450b-a4da-9533c5754645"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run hyperparameter search\n",
        "tuner.search(X_train, y_train, epochs=3, validation_split=0.2)\n",
        "\n",
        "# Get the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate the best model\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "y_pred_binary_best = (y_pred_best > 0.5).astype(int)\n",
        "\n",
        "accuracy_best = accuracy_score(y_test, y_pred_binary_best)\n",
        "precision_best = precision_score(y_test, y_pred_binary_best)\n",
        "recall_best = recall_score(y_test, y_pred_binary_best)\n",
        "f1_best = f1_score(y_test, y_pred_binary_best)\n",
        "roc_auc_best = roc_auc_score(y_test, y_pred_best)\n",
        "\n",
        "print(\"\\nBest Model Evaluation Metrics:\")\n",
        "print(f'Accuracy: {accuracy_best:.4f}')\n",
        "print(f'Precision: {precision_best:.4f}')\n",
        "print(f'Recall: {recall_best:.4f}')\n",
        "print(f'F1 Score: {f1_best:.4f}')\n",
        "print(f'ROC AUC: {roc_auc_best:.4f}')"
      ],
      "metadata": {
        "id": "6CVrq1RTB5XV",
        "outputId": "36cdf80f-f89a-4f3b-b74d-29e559a19c25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "64                |64                |embedding_dim\n",
            "128               |128               |rnn_units\n",
            "0.2               |0.2               |dropout_rate\n",
            "2                 |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "2                 |2                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "Epoch 1/2\n",
            "\u001b[1m  8/535\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11:50\u001b[0m 1s/step - accuracy: 0.5905 - loss: 0.6909"
          ]
        }
      ]
    }
  ]
}