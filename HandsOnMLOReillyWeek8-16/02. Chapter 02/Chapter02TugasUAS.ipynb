{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Create a workspace directory for your Machine Learning code and\n",
        "datasets"
      ],
      "metadata": {
        "id": "6z1c_FzOLG8M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Bp1y72jK0BJ"
      },
      "outputs": [],
      "source": [
        "$ export ML_PATH=\"$HOME/ml\" # You can change the path if you prefer\n",
        "$ mkdir -p $ML_PATH"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check to see if pip is installed"
      ],
      "metadata": {
        "id": "moxzoYUALM7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$ python3 -m pip --version"
      ],
      "metadata": {
        "id": "VeDF8pSWLCnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upgrade the pip module"
      ],
      "metadata": {
        "id": "IHwTMLDKLRVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$ python3 -m pip install --user -U pip"
      ],
      "metadata": {
        "id": "P0vc3ehiLE32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install all the required modules and their dependencies"
      ],
      "metadata": {
        "id": "nGt7BCAeLarx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$ python3 -m pip install -U jupyter matplotlib numpy pandas scipy scikit-learn"
      ],
      "metadata": {
        "id": "YYUeO5xsLZ47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Register a virtualenv to Jupyter and give it a name"
      ],
      "metadata": {
        "id": "ZZXc9JUALldf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$ python3 -m ipykernel install --user --name=python3"
      ],
      "metadata": {
        "id": "pJbH_13XLhWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Start up Jupyter"
      ],
      "metadata": {
        "id": "nGsJtFTbLt1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "$ jupyter notebook"
      ],
      "metadata": {
        "id": "XG73T_wyLwaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetch the data"
      ],
      "metadata": {
        "id": "rskdkelXMDGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib\n",
        "\n",
        "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
        "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
        "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
        "\n",
        "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
        "    os.makedirs(housing_path, exist_ok=True)\n",
        "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
        "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
        "    housing_tgz = tarfile.open(tgz_path)\n",
        "    housing_tgz.extractall(path=housing_path)\n",
        "    housing_tgz.close()"
      ],
      "metadata": {
        "id": "-DxJ5E8bL4nN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the data using pandas"
      ],
      "metadata": {
        "id": "fQg5w8JMMKZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_housing_data(housing_path=HOUSING_PATH):\n",
        "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
        "    return pd.read_csv(csv_path)"
      ],
      "metadata": {
        "id": "l064LaS_MGKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find out what categories exist and how many districts belong to each category"
      ],
      "metadata": {
        "id": "g0hRKgspMSjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> housing[\"ocean_proximity\"].value_counts()"
      ],
      "metadata": {
        "id": "2TESNi4zMN4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call `hist()` to plot a histogram for each numerical attribute"
      ],
      "metadata": {
        "id": "r9mOA7sDMgBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline # only in a Jupyter notebook\n",
        "import matplotlib.pyplot as plt\n",
        "housing.hist(bins=50, figsize=(20,15))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4Ajw91aiMXjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a test set from 20% of the dataset"
      ],
      "metadata": {
        "id": "FJ2r0ihKMzsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def split_train_test(data, test_ratio):\n",
        "    shuffled_indices = np.random.permutation(len(data))\n",
        "    test_set_size = int(len(data) * test_ratio)\n",
        "    test_indices = shuffled_indices[:test_set_size]\n",
        "    train_indices = shuffled_indices[test_set_size:]\n",
        "    return data.iloc[train_indices], data.iloc[test_indices]"
      ],
      "metadata": {
        "id": "OtQ5fD9LMtN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ">>> train_set, test_set = split_train_test(housing, 0.2)\n",
        ">>> len(train_set)"
      ],
      "metadata": {
        "id": "wz7Ln_xVNAGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ">>> len(test_set)"
      ],
      "metadata": {
        "id": "8ncEECa2NBf-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute a hash of each instance’s identifier and put that instance in the test set"
      ],
      "metadata": {
        "id": "oAZIdM6gNNmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from zlib import crc32\n",
        "def test_set_check(identifier, test_ratio):\n",
        "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
        "\n",
        "def split_train_test_by_id(data, test_ratio, id_column):\n",
        "    ids = data[id_column]\n",
        "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
        "    return data.loc[~in_test_set], data.loc[in_test_set]"
      ],
      "metadata": {
        "id": "bRoTMpzmNFyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the row index as the ID to solve housing dataset not having an identifier column"
      ],
      "metadata": {
        "id": "Py-seBLHNksA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing_with_id = housing.reset_index() # adds an `index` column\n",
        "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")"
      ],
      "metadata": {
        "id": "KXzZ45_6Nd-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the most stable features to build a unique identifier if the new data doesnt get appended to the end of the dataset and that rows gets deleted"
      ],
      "metadata": {
        "id": "ARsWXQUONxOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
        "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")"
      ],
      "metadata": {
        "id": "G_VJ3LY9NsRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other ways (functions) to split datasets into multiple subsets with `random_state` parameter setting the random generator\n",
        "seed and passing it multiple datasets with an identical number of rows to split them on the same indices"
      ],
      "metadata": {
        "id": "Yagrg54TOIRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "l-Rc3NeHOvep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create an income category attribute with five categories"
      ],
      "metadata": {
        "id": "V2FnF_j6O6Kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
        "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
        "                               labels=[1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "id": "E9ZoZFa-O1dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating histogram of income categories"
      ],
      "metadata": {
        "id": "cy8xsuc2PF4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"income_cat\"].hist()"
      ],
      "metadata": {
        "id": "5QDfvBgUPB4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do stratified sampling based on the income category"
      ],
      "metadata": {
        "id": "pPa1OEFIPRpH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
        "    strat_train_set = housing.loc[train_index]\n",
        "    strat_test_set = housing.loc[test_index]"
      ],
      "metadata": {
        "id": "u3gClu5XPJ4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the income category proportions in the test set"
      ],
      "metadata": {
        "id": "No1OBiq5PW8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
      ],
      "metadata": {
        "id": "iPIERnn0PT_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove the `income_cat` attribute so the data is back to its original\n",
        "state"
      ],
      "metadata": {
        "id": "t24Yi7y0Pfdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for set_ in (strat_train_set, strat_test_set):\n",
        "    set_.drop(\"income_cat\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "j5l1zz4oPbo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a copy to play with so it\n",
        "wont harm the training set"
      ],
      "metadata": {
        "id": "f79iwg7BPy5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing = strat_train_set.copy()"
      ],
      "metadata": {
        "id": "DVq6msCmPuNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a scatterplot of all districts."
      ],
      "metadata": {
        "id": "9an6Lz7YP8Cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")"
      ],
      "metadata": {
        "id": "D-Zu53aSP5yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting the alpha option to 0.1 for easier visualization of the places\n",
        "with high density data points."
      ],
      "metadata": {
        "id": "rlsYdGrBQG48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
      ],
      "metadata": {
        "id": "u29dWMmvQAWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make the patterns stand out. The radius of each circle represents\n",
        "the district’s population (option s), and the color represents the price (option c). We\n",
        "will use a predefined color map (option cmap) called jet, which ranges from blue\n",
        "(low values) to red (high prices)."
      ],
      "metadata": {
        "id": "AaSOolMIQXxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
        "             s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
        "             c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
        ")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "xNg0LihIQRkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the standard correlation\n",
        "coefficient between every pair of attributes"
      ],
      "metadata": {
        "id": "bWfVKZKhQtsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = housing.corr()"
      ],
      "metadata": {
        "id": "cGDayRhiQwuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at how much each attribute correlates with the median house value"
      ],
      "metadata": {
        "id": "IODbotXzQ4EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "mjzDQyyrQ3sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Focusing on a few promising\n",
        "attributes that seem most correlated with the median housing value"
      ],
      "metadata": {
        "id": "HstFLbSrRDsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
        "              \"housing_median_age\"]\n",
        "scatter_matrix(housing[attributes], figsize=(12, 8))"
      ],
      "metadata": {
        "id": "0eQNg1lNQ84E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zoom in on the correlation scatterplot of `median_income` and `median_house_value`"
      ],
      "metadata": {
        "id": "ahjRwUyeRQDG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\", alpha=0.1)"
      ],
      "metadata": {
        "id": "H68SCY6zRKs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create new attributes"
      ],
      "metadata": {
        "id": "RF5eSGb5RsSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
        "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
        "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
      ],
      "metadata": {
        "id": "wQ6U-41jRnun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the correlation matrix"
      ],
      "metadata": {
        "id": "Q3lnrp8MRxjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> corr_matrix = housing.corr()\n",
        ">>> corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "U2stJpeuRw5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Revert to a clean training set and separate the predictors and the labels"
      ],
      "metadata": {
        "id": "DKSN9L6OR6mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
        "housing_labels = strat_train_set[\"median_house_value\"].copy()"
      ],
      "metadata": {
        "id": "yC3f1Z9bR2jL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking care of missing values in `total_bedrooms` with options:\n",
        "1. Get rid of the corresponding districts.\n",
        "2. Get rid of the whole attribute.\n",
        "3. Set the values to some value (zero, the mean, the median, etc.)."
      ],
      "metadata": {
        "id": "i-LeOKKWSEbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing.dropna(subset=[\"total_bedrooms\"]) # option 1\n",
        "housing.drop(\"total_bedrooms\", axis=1) # option 2\n",
        "median = housing[\"total_bedrooms\"].median() # option 3\n",
        "housing[\"total_bedrooms\"].fillna(median, inplace=True)"
      ],
      "metadata": {
        "id": "RD7-kx0qSBej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-Learn's handy class to take care of missing values"
      ],
      "metadata": {
        "id": "ysOBT-HQSjVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"median\")"
      ],
      "metadata": {
        "id": "N0aCPrXNSd98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a copy of the data without the text attribute `ocean_proximity`"
      ],
      "metadata": {
        "id": "pzkQHWQsSwB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing_num = housing.drop(\"ocean_proximity\", axis=1)"
      ],
      "metadata": {
        "id": "WlHd25D-St7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fit the imputer instance to the training data"
      ],
      "metadata": {
        "id": "BbAtVLH4S8LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imputer.fit(housing_num)"
      ],
      "metadata": {
        "id": "FarAB2vCS5R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply the imputer to all the numerical attributes"
      ],
      "metadata": {
        "id": "nPDJGPDZTBOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> imputer.statistics_\n",
        ">>> housing_num.median().values"
      ],
      "metadata": {
        "id": "KhASHngNS9pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use “trained” imputer to transform the training set by replacing\n",
        "missing values with the learned medians"
      ],
      "metadata": {
        "id": "7pW7W1P3TI8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = imputer.transform(housing_num)"
      ],
      "metadata": {
        "id": "ztMSuS5rTH26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to put it back into a pandas DataFrame"
      ],
      "metadata": {
        "id": "BuuppEB5TVid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)"
      ],
      "metadata": {
        "id": "z1acL-XMTPkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at `ocean_proximity`'s value for the first 10 instances"
      ],
      "metadata": {
        "id": "bId0_sTeTi-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> housing_cat = housing[[\"ocean_proximity\"]]\n",
        ">>> housing_cat.head(10)"
      ],
      "metadata": {
        "id": "3Mx9fZzBTgjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert categories from text to numbers with Scikit-Learn’s `OrdinalEncoder` class"
      ],
      "metadata": {
        "id": "9tzjQ68wTtbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> from sklearn.preprocessing import OrdinalEncoder\n",
        ">>> ordinal_encoder = OrdinalEncoder()\n",
        ">>> housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
        ">>> housing_cat_encoded[:10]"
      ],
      "metadata": {
        "id": "OdpgfVJuTrJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the list of categories using the `categories_ instance` variable"
      ],
      "metadata": {
        "id": "x6uxVgfbT9Ed"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> ordinal_encoder.categories_"
      ],
      "metadata": {
        "id": "RGVqt6bdT7Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-Learn's `OneHotEncoder` class to convert categorical values into one-hot vectors"
      ],
      "metadata": {
        "id": "VqCL2IpMUIEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> from sklearn.preprocessing import OneHotEncoder\n",
        ">>> cat_encoder = OneHotEncoder()\n",
        ">>> housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
        ">>> housing_cat_1hot"
      ],
      "metadata": {
        "id": "mDiRHRtJUF0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To convert it to a (dense) NumPy array"
      ],
      "metadata": {
        "id": "L37JBLf5USB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> housing_cat_1hot.toarray()"
      ],
      "metadata": {
        "id": "WANazGhUUN91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the list of categories"
      ],
      "metadata": {
        "id": "lzlS_3LeeB9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> cat_encoder.categories_"
      ],
      "metadata": {
        "id": "ONS11vtbd_wU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adds combined attributes with Custom Transformers"
      ],
      "metadata": {
        "id": "Oo_yOyX6etlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
        "\n",
        "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
        "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
        "    def fit(self, X, y=None):\n",
        "        return self # nothing else to do\n",
        "    def transform(self, X):\n",
        "    rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
        "    population_per_household = X[:, population_ix] / X[:, households_ix]\n",
        "    if self.add_bedrooms_per_room:\n",
        "        bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
        "        return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
        "    else:\n",
        "        return np.c_[X, rooms_per_household, population_per_household]\n",
        "\n",
        "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
        "housing_extra_attribs = attr_adder.transform(housing.values)"
      ],
      "metadata": {
        "id": "gWr4ZPmyeIA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-Learn's data transformation Pipeline class for the numerical attributes"
      ],
      "metadata": {
        "id": "0vtfFPzsfBiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "num_pipeline = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
        "        ('attribs_adder', CombinedAttributesAdder()),\n",
        "        ('std_scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "housing_num_tr = num_pipeline.fit_transform(housing_num)"
      ],
      "metadata": {
        "id": "Ub9sFfjxessz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single transformer to handle all columns (categorical columns and the numerical columns)"
      ],
      "metadata": {
        "id": "uk5gscoefaVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_attribs = list(housing_num)\n",
        "cat_attribs = [\"ocean_proximity\"]\n",
        "\n",
        "full_pipeline = ColumnTransformer([\n",
        "        (\"num\", num_pipeline, num_attribs),\n",
        "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
        "    ])\n",
        "\n",
        "housing_prepared = full_pipeline.fit_transform(housing)"
      ],
      "metadata": {
        "id": "ypaz5OQafSYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a Linear Regression model"
      ],
      "metadata": {
        "id": "LUgBXjYHf1kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(housing_prepared, housing_labels)"
      ],
      "metadata": {
        "id": "9-L7IdN-fxeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try Linear Regression model on a few\n",
        "instances from the training set"
      ],
      "metadata": {
        "id": "axi4MSe0f-uN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> some_data = housing.iloc[:5]\n",
        ">>> some_labels = housing_labels.iloc[:5]\n",
        ">>> some_data_prepared = full_pipeline.transform(some_data)\n",
        ">>> print(\"Predictions:\", lin_reg.predict(some_data_prepared))\n",
        ">>> print(\"Labels:\", list(some_labels))"
      ],
      "metadata": {
        "id": "fimURDhZf4Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measure this regression model’s RMSE on the whole training"
      ],
      "metadata": {
        "id": "hSTPhQyDgISK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> from sklearn.metrics import mean_squared_error\n",
        ">>> housing_predictions = lin_reg.predict(housing_prepared)\n",
        ">>> lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        ">>> lin_rmse = np.sqrt(lin_mse)\n",
        ">>> lin_rmse"
      ],
      "metadata": {
        "id": "-E-MtxLQgDQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a DecisionTreeRegressor model"
      ],
      "metadata": {
        "id": "hTTc6HXLgOJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg = DecisionTreeRegressor()\n",
        "tree_reg.fit(housing_prepared, housing_labels)"
      ],
      "metadata": {
        "id": "EMsRatT5gLO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the trained model on the training set"
      ],
      "metadata": {
        "id": "TlgNoicfgT23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> housing_predictions = tree_reg.predict(housing_prepared)\n",
        ">>> tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
        ">>> tree_rmse = np.sqrt(tree_mse)\n",
        ">>> tree_rmse"
      ],
      "metadata": {
        "id": "eWf-vHGwgRl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scikit-Learn’s K-fold cross-validation feature to evaluate the Decision Tree model"
      ],
      "metadata": {
        "id": "QrW6hmmigjNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(tree_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
        "tree_rmse_scores = np.sqrt(-scores)"
      ],
      "metadata": {
        "id": "qcCnceoQgZFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the results"
      ],
      "metadata": {
        "id": "wuhoDZj_gwNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> def display_scores(scores):\n",
        "...     print(\"Scores:\", scores)\n",
        "...     print(\"Mean:\", scores.mean())\n",
        "...     print(\"Standard deviation:\", scores.std())\n",
        "...\n",
        ">>> display_scores(tree_rmse_scores)"
      ],
      "metadata": {
        "id": "40tkWzglgnzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the same scores for the Linear Regression model"
      ],
      "metadata": {
        "id": "P3rGIkFPg4ED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels, scoring=\"neg_mean_squared_error\", cv=10)\n",
        "...\n",
        ">>> lin_rmse_scores = np.sqrt(-lin_scores)\n",
        ">>> display_scores(lin_rmse_scores)"
      ],
      "metadata": {
        "id": "fvH96oDigxYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a RandomForestRegressor model"
      ],
      "metadata": {
        "id": "25Vbp1mchEfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> from sklearn.ensemble import RandomForestRegressor\n",
        ">>> forest_reg = RandomForestRegressor()\n",
        ">>> forest_reg.fit(housing_prepared, housing_labels)\n",
        ">>> [...]\n",
        ">>> forest_rmse\n",
        ">>> display_scores(forest_rmse_scores)"
      ],
      "metadata": {
        "id": "XTjYvIFQhA_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Searching for the best combination of hyperparameter values for the RandomForestRegressor"
      ],
      "metadata": {
        "id": "Wd10N3WBhQfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = [\n",
        "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
        "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
        "    ]\n",
        "\n",
        "forest_reg = RandomForestRegressor()\n",
        "\n",
        "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           return_train_score=True)\n",
        "\n",
        "grid_search.fit(housing_prepared, housing_labels)"
      ],
      "metadata": {
        "id": "gPlrrPZ7hP6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the best combination of parameters"
      ],
      "metadata": {
        "id": "J0QsN1syhuoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> grid_search.best_params_"
      ],
      "metadata": {
        "id": "zfabJdk_hpq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the best estimator directly"
      ],
      "metadata": {
        "id": "9JpkXBgTh0pQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> grid_search.best_estimator_"
      ],
      "metadata": {
        "id": "M-dgGXwWhxXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Look at the evaluation scores"
      ],
      "metadata": {
        "id": "SgaFkkmnh8Ur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> cvres = grid_search.cv_results_\n",
        ">>> for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
        "... print(np.sqrt(-mean_score), params)"
      ],
      "metadata": {
        "id": "bBzIhrwuh43X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indicate the relative importance of each\n",
        "attribute for making accurate predictions with RandomForestRegressor"
      ],
      "metadata": {
        "id": "DXiMNSAUiBTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> feature_importances = grid_search.best_estimator_.feature_importances_\n",
        ">>> feature_importances"
      ],
      "metadata": {
        "id": "9n0feiEyh_kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the scores next to their corresponding attribute names"
      ],
      "metadata": {
        "id": "mI9ZM-EDiM-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
        ">>> cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
        ">>> cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
        ">>> attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
        ">>> sorted(zip(feature_importances, attributes), reverse=True)"
      ],
      "metadata": {
        "id": "AWV7r4RViKgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the predictors and the labels from your\n",
        "test set, run your `full_pipeline` to transform the data, and evaluate the final model\n",
        "on the test set"
      ],
      "metadata": {
        "id": "6ci8KFp6iZZ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = grid_search.best_estimator_\n",
        "\n",
        "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
        "y_test = strat_test_set[\"median_house_value\"].copy()\n",
        "\n",
        "X_test_prepared = full_pipeline.transform(X_test)\n",
        "\n",
        "final_predictions = final_model.predict(X_test_prepared)\n",
        "\n",
        "final_mse = mean_squared_error(y_test, final_predictions)\n",
        "final_rmse = np.sqrt(final_mse) # => evaluates to 47,730.2"
      ],
      "metadata": {
        "id": "q1mVLT2NiQF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute a 95% confidence interval for the generalization error"
      ],
      "metadata": {
        "id": "3tJx3jRrirAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ">>> from scipy import stats\n",
        ">>> confidence = 0.95\n",
        ">>> squared_errors = (final_predictions - y_test) ** 2\n",
        ">>> np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
        "... loc=squared_errors.mean(),\n",
        "... scale=stats.sem(squared_errors)))"
      ],
      "metadata": {
        "id": "Z5WREGzliqKp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}